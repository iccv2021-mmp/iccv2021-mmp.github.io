<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">
<head>
  <title>ICCV 2021 Multi-camera Multiple People Tracking Workshop</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" />
  <link rel="stylesheet" href="css/simple.css" />
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css' />
  <style>
      .center-cropped {
        object-fit: cover;
        object-position: center;
        width: 100%;
        height: 50%;
      }
  </style>
</head>
<body>

    <div class="header">
        <div class="headertext">
            <div class="title"> ICCV 2021 Multi-camera Multiple People Tracking Workshop </div>
        </div>
    </div>
<!-- Navigation -->
	<nav class="navbar navbar-inverse navbar-static-top" role="navigation">
	  <div class="container">
		<div class="navbar-header">
		  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
		  <ul class="nav navbar-nav">
				  <li><a href="#overview">Workshop Overview</a></li>
          <li><a href="subpage/dataset.html">Dataset</a></li>
				  <li><a href="#challenge">Challenge</a></li> 
				  <li><a href="#schedule">Schedule</a></li> 
				  <li><a href="#speakers">Invited Speakers</a></li> 
				  <li><a href="#committee">Advisory Committee</a></li> 
				  <li><a href="#organizers">Organizers</a></li> 
		  </ul>
		</div>
	  </div>
	</nav>
  
  <!-- Page Content -->
    <div class="container">

        <div class="row">
            <!-- Entries Column -->
            <div class="col-md-12">
                <!-- <h2 id="overview">Workshop Overview</h2> -->
                <div style="font-family: sans-serif; font-size: 24px;">
                <div style="margin-top:3%; text-align:justify;">             
                <p>We propose to organize this Multi-camera Multiple People Tracking workshop, aiming to gather academic and industry community together to tackle indoor multiple people tracking using multiple RGB cameras. </p>
                <h2 id="overview">Overview</h2>
		<p>Multiple object tracking is one of the most basic and most important tasks in computer vision. It is one of the fundamental research topics in understanding visual content. It has numerous applications in indoor navigation, motion capture, human computer interaction, robotics etc. </p>
		<p>For single-camera tracking, there are several datasets and benchmarks, which stimulate novel ideas of tracking models using sequential information. For multi-camera tracking, data collection and labeling are much more difficult. Thus, there are only a few small datasets available and no common benchmarks.</p>
		<p>To support the community to develop more efficient and novel tracking algorithms, we construct a multi-camera multiple people tracking dataset. We expect our datasets can also be served as an evaluation benchmark for this task. This challenge invites all research teams to participate, and dataset will be released to the research community. We invite academic and industrial researchers to participate in this multi-camera multiple people tracking contest.</p>
                </div>
                </div>
           </div>
           <div class="col-md-12">
              <div style="font-family: sans-serif; font-size: 24px;">
              <div style="margin-top:3%; text-align:justify;">
                <h2 id="challenge">Multi-camera Multiple People Tracking (MMP-Tracking) Challenge</h2>
                  <p>
                    MMP-Tracking Challenge aims to push the state of the art multi-camera multiple people 
                    tracking algorithms forward. The participants will receive an annotated training set and a test set without annotations.
                  </p>

                  <p>
                    There are two subtracks in this challenge. (1) Evaluating tracking results from topdown view; (2) Evaluating tracking results from each camera
                    view, then aggregate together for final metric. 
                  </p>

                  <p>
                    For subtrack (1), using camera calibration files provided, one can mapping the ground plane in each camera view into a world coordinate shared by all cameras. Then discretize the world coordinate with voxel size 20mm to get topdown view map. We provide ground truth label of person footpoint coordinates in topdown view map. During evaluation, we compute false positive(FP), false negative(FN) and true positive(TP) by assigning detected person footpoint to ground truth footpoint using Hungarian matching. We impose that a detected footpoint can be assigned to ground truth only if they are less than 0.5m away (25pixel distance in topdown map). After getting FP, FN and TP, we will compute IDF1 and MOTA as our final score.
                  </p>

                  <p>
                    For subtrack (2), following the same evaluation procedure widely used in <a href='https://motchallenge.net/vis/'>MOT</a>, we compute FP, FN and TP for each camera view independently (detected bounding box and ground truth bounding box can be matched only their IOU>0.5). After getting results from each camera view, we average over all these results to computer our final metrics. We will use IDF1 and MOTA as our final score.
                  </p>

                  <p>
                    Our evaluation codes are based on <a href="https://github.com/cheind/py-motmetrics/"> py-motmetrics </a>. 
                    The evaluation codes can be downloaded <a href="https://github.com/iccv2021-mmp/mmp-tracking-helper/"> here </a>
                    for local usage by participants.
                    We use CodaLab as our evaluation server <a href="https://competitions.codalab.org/competitions/33729"> link </a>.
                  </p>
              </div>
              </div>
           </div>

           <div class="col-md-12">
                <h2 id="schedule">Schedule</h2>
                <h3>
                <ul>
                  <li>July 18th: Training and validation data available</li>
                  <li>July 25th: Testing phase begins</li>
                  <li>Sep 30th: Competition ends (challenge paper submission - optional)</li>
                </ul>
                </h3>

                <h3>
                  <table style="width:100%">
                    <tr>
                      <th width="23%">Time (EDT) Oct 16th</th>
                      <th width="47%">Session</th>
                      <th width="30%">Note</th>
                    </tr>
                    <tr>
                      <td>10:30am ~ 10:35am</td>
                      <td>Opening Remark</td>
                      <td>Dr. Zicheng Liu</td>
                    </tr>
                    <tr>
                      <td>10:35am ~ 11:20am</td>
                      <td>Keynote: Multi-Object and Multi-Camera Tracking</td>
                      <td>Prof. Mubarak Shah</td>
                    </tr>
                    <tr>
                      <td>11:20am ~ 11:35am</td>
                      <td>Dataset introduction and Winner Announcement</td>
                      <td></td>
                    </tr>
                    <tr>
                      <td>11:35am ~ 12:05pm</td>
                      <td>Special Session: Ethics, privacy and diversity in people tracking</td>
                      <td>Host: Dr. Zicheng Liu, Panelist: Dr. Houdong Hu, Prof. Ming-Hsuan Yang, Prof. Haibin Ling</td>
                    </tr>
                    <tr>
                      <td>12:05pm ~ 12:10pm</td>
                      <td>break</td>
                      <td></td>
                    </tr>
                    <tr>
                      <td>12:10am ~ 12:55pm</td>
                      <td>Keynote: Towards robust cross-domain object detection </td>
                      <td>Dr. Xin Wang</td>
                    </tr>
                    <tr>
                      <td>12:55pm ~ 13:10pm</td>
                      <td>Winner Talk: From Camera-view Tracklets to Topdown-view Trajectories: Information Aggregation at Different Levels </td>
                      <td>Fei Du, Alibaba Group</td>
                    </tr>
                    <tr>
                      <td>13:10pm ~ 13:25pm</td>
                      <td>Winner Talk: TBD</td>
                      <td>Size Wu, University of Science and Technology of China</td>
                    </tr>
                    <tr>
                      <td>13:25pm ~ 13:40pm</td>
                      <td>Winner Talk: Head-based Multi-camera Multiple People 3D Tracking</td>
                      <td>Fan Yang, Fujitsu Research</td>
                    </tr>
                    <tr>
                      <td>13:40pm ~ 13:45pm</td>
                      <td>break</td>
                      <td></td>
                    </tr>
                    <tr>
                      <td>13:45pm ~ 14:00pm</td>
                      <td>Winner Talk: Multi-camera Multiple People Tracking</td>
                      <td>Jie Zhang, Hikvision Research Institute</td>
                    </tr>
                    <tr>
                      <td>14:00pm ~ 14:15pm</td>
                      <td>Winner Talk: Multi-Expert Multiple Object Tracking (ME-MOT)</td>
                      <td>Hung-Min Hsu, Wyze Labs, Inc. AI Team</td>
                    </tr>
                    <tr>
                      <td>14:15pm ~ 14:30pm</td>
                      <td>Winner Talk: TBD</td>
                      <td>Cheng-Yen Yang, Information Processing Lab, University of Washington</td>
                    </tr>
                    <tr>
                      <td>14:30pm ~ 15:15pm</td>
                      <td>Keynote: Benchmarking and Diagnosis of Visual Tracking Algorithms</td>
                      <td>Prof. Haibin Ling</td>
                    </tr>
                  </table>
                </h3>
           </div>


           <div class="col-md-12">
                <h2 id="speakers">Invited Speakers</h2>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://xinw.ai/assets/images/photo.JPG" width="80%" height="auto" style="padding-bottom:30px;">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                    <h3><a href="https://xinw.ai/">Dr. Xin Wang</a></h3>
                    <p>Dr. Xin Wang is a Ph.D. student at UC Berkeley, working with Prof. Trevor Darrell and Prof. Joseph E. Gonzalez. She is part of the BAIR Lab, RISE Lab, and BDD Lab. Her research interest lies at the intersection of computer vision, machine learning and learning systems. </p>
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://www3.cs.stonybrook.edu/~hling/photo/Ling-18.jpg" width="60%" height="auto" style="padding-bottom:30px;">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                    <h3><a href="https://www3.cs.stonybrook.edu/~hling/">Prof. Haibin Ling</a></h3>
                    <p>SUNY Empire Innovation Professor at Stony Brook University. His research interests include computer vision, augmented reality, medical image analysis, visual privacy protection, and human computer interaction. He received Best Student Paper Award of ACM UIST in 2003 and NSF CAREER Award in 2014. He serves as associate editors for IEEE Trans. on Pattern Analysis and Machine Intelligence (PAMI), Pattern Recognition (PR), and Computer Vision and Image Understanding (CVIU). He has served as Area Chairs various times for CVPR and ECCV.</p>
                  </div>
                </div>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://www.crcv.ucf.edu/wp-content/uploads/2018/10/Dr_Shah.jpg" width="60%" height="auto" style="padding-bottom:30px;">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                    <h3><a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Prof. Mubarak Shah</a></h3>
                    <p>Trustee Chair Professor of Computer Science, is the founding director of the Center for Research in Computer Vision at UCF. His research interests include: video surveillance, visual tracking, human activity recognition, visual analysis of crowded scenes, video registration, UAV video analysis, etc. Dr. Shah is a fellow of the National Academy of Inventors, IEEE, AAAS, IAPR and SPIE. In 2006, he was awarded a Pegasus Professor award, the highest award at UCF.</p>
                  </div>
                </div>
           </div>

           <div class="col-md-12">
                <h2 id="committee">Advisory Committee</h2>
                <div class="row  align-items-bottom justify-content-center">
                  <div class="col-lg-4">
                      <img src="https://chavdarova.github.io/photos/Tatjana_Chavdarova2.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                      <img src="https://www3.cs.stonybrook.edu/~hling/photo/Ling-18.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                      <img src="img/wy_2.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-4">
                    <h3><a href="https://chavdarova.github.io">Dr. Tatjana Chavdarova</a></h3>
                    <p>Postdoctoral researcher in the Machine Learning and Optimization (MLO) lab at EPFL.</p>
                  </div>
                  <div class="col-lg-4">
                    <h3><a href="https://www3.cs.stonybrook.edu/~hling/">Prof. Haibin Ling</a></h3>
                    <p>SUNY Empire Innovation Professor, Dept of Computer Science, Stony Brook University.</p>
                  </div>
                  <div class="col-lg-4">
                    <h3><a href="http://users.eecs.northwestern.edu/~yingwu/">Prof. Ying Wu</a></h3>
                    <p>Full professor in the Department of Electrical Engineering and Computer Science and the Department of Computer Science at Northwestern University.<p>
                  </div>
                </div>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://lh5.googleusercontent.com/-dV93x6frPFw/UTkTgJT7huI/AAAAAAAAalA/XhMeDDCaHSs/w448-h375-o-k/Jiebo-Bigdata.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                      <img src="https://faculty.ucmerced.edu/mhyang/images/mhyang2005_70.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                      <img src="https://www.crcv.ucf.edu/wp-content/uploads/2018/10/Dr_Shah.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-4">
                    <h3><a href="https://cs.rochester.edu/u/jluo/">Prof. Jiebo Luo</a></h3>
                    <p>Fully Professor at Department of Computer Science, University of Rochester.</p>
                  </div>
                  <div class="col-lg-4">
                    <h3><a href="https://faculty.ucmerced.edu/mhyang/">Prof. Ming-Hsuan Yang</a></h3>
                    <p>Professor in Electrical Engineering and Computer Science at University of California, Merced.</p>
                  </div>
                  <div class="col-lg-4">
                    <h3><a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Prof. Mubarak Shah</a></h3>
                    <p>UCF Trustee Chair Professor, Director.<p>
                  </div>
                </div>
        </div>
        <div class="col-md-12">
                <h2 id="organizers">Organizers</h2>
                <div class="row">
                  <div class="col-lg-3">
                      <img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=5fHHi24AAAAJ&citpid=1" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="img/quanzeng.png" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="img/Peng_chu.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="img/will_boyd.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-3">
                    <h4>Xiaotian Han, Microsoft</h4>
                  </div>
                  <div class="col-lg-3">
                    <h4>Quanzeng You, Microsoft</h3>
                  </div>
                  <div class="col-lg-3">
                    <h4>Peng Chu, Microsoft</h4>
                  </div>
                  <div class="col-lg-3">
                    <h4>Will Boyd, Microsoft</h3>
                  </div>
                </div>

                <div class="row">
                  <div class="col-lg-3">
                      <img src="img/jia_li.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="img/Houdong_profile.png" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="img/jiangwang.png" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-3">
                    <h4>Jia Li, DawnLigth</h3>
                  </div>
                  <div class="col-lg-3">
                    <h4>Houdong Hu, Microsoft</h4>
                  </div>
                  <div class="col-lg-3">
                    <h4>Jiang Wang, Microsoft</h4>
                  </div>
                  <div class="col-lg-3">
                    <h4>Zicheng Liu, Microsoft</h3>
                  </div>
               </div>
            </div>
        </div>

    </div>
    <!-- /.container -->
    
    <!-- Other people may like it too! -->
    <a style="color:#b5bec9;font-size:0.8em; float:right;" href="https://github.com/mavroudisv/plain-academic">Plain Academic</a> 

    <footer style="background-color:#444; color:#fdfdfd; padding:40px 0;">
        <p style="text-align:center; font-family: sans-serif; font-size: 14px;">
          Workshop and Challenge questions?<br/>
          Email <a href="iccv2021mmp@outlook.com">iccv2021mmp@outlook.com</a><br/>
          Microsoft Azure Computer Vision Team
        </p>
    </footer>
    
</body>

</html>
