<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">
<head>
  <title>ICCV 2021 Multi-camera Multiple People Tracking Workshop</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" />
  <link rel="stylesheet" href="css/simple.css" />
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css' />
  <style>
      .center-cropped {
        object-fit: cover;
        object-position: center;
        width: 100%;
        height: 50%;
      }
  </style>
</head>
<body>

    <div class="header">
        <div class="headertext">
            <div class="title"> ICCV 2021 Multi-camera Multiple People Tracking Workshop </div>
        </div>
    </div>
<!-- Navigation -->
	<nav class="navbar navbar-inverse navbar-static-top" role="navigation">
	  <div class="container">
		<div class="navbar-header">
		  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
		  <ul class="nav navbar-nav">
				  <li><a href="#overview">Workshop Overview</a></li>
				  <li><a href="#challenge">MMulti-camera Multiple People TrackingMP Challenge</a></li> 
				  <li><a href="#schedule">Schedule</a></li> 
				  <li><a href="#speakers">Invited Speakers</a></li> 
				  <li><a href="#committee">Advisory Committee</a></li> 
				  <li><a href="#organizers">Organizers</a></li> 
		  </ul>
		</div>
	  </div>
	</nav>
  
  <!-- Page Content -->
    <div class="container">

        <div class="row">
            <!-- Entries Column -->
            <div class="col-md-12">
                <h2 id="overview">Workshop Overview</h2>
                <div style="font-family: sans-serif; font-size: 20px;">
                <div style="margin-top:3%; text-align:justify;">                
                <p>We propose to organize this Multi-camera Multiple People Tracking workshop, aiming to gather academic and industry community together to tackle indoor multiple people tracking using multiple RGB cameras. </p>
                <h3>Motivation</h3>
                <p>In recent years, with the availability of increasingly cheap parallel processing power and the advancement of machine learning algorithms, the computer vision community has achieved impressive results on several fundamental vision tasks, such as image classification, object detection, instance segmentation, etc. In general, the community mainly focuses on developing machine learning models using static images. This can be primarily attributed to the fact that images are relatively easier to label compared with videos. As a result, various large scale image datasets and benchmarks on different vision tasks have been constructed and shared with the research community, which is essential for deep learning to succeed. However, most real-world computer vision applications need to deal with videos, especially person-centric videos. Currently, a widely used solution is to integrate deep neural network models trained on images into systems that deal with videos. This is also true for people tracking. Tracking by detection is a common approach for multiple object tracking, where the crucial component, object detector, is usually trained on images. </p>
                <p>It is indisputable that multiple people tracking is one of the most basic and most important tasks in computer vision. It has numerous applications in security surveillance, motion capture, human computer interaction, robotics etc. For single-camera tracking, there are several datasets and benchmarks, which stimulate novel ideas of tracking models using sequential information. For multi-camera tracking, data collection and labeling are much more difficult. Thus, there are only a few small datasets available and no common benchmarks. We argue that in the era of deep learning, this will prohibit the community from building effective neural network models for this challenging task.</p>
                <p>To support the community to develop more efficient and novel neural network models, we plan to construct the largest multi-camera multiple people tracking dataset. We expect our datasets can also be served as an evaluation benchmark for this task. This challenge invites all research teams to participate dataset will be released to the community. We invite academic and industrial researchers to participate in this multi-camera multiple people tracking contest.</p>
                </div>
                </div>
           </div>
           <div class="col-md-12">
                <h2 id="challenge">Multi-camera Multiple People (MMP) Tracking Challenge</h2>
                <h3>TBD</h3>
           </div>

           <div class="col-md-12">
                <h2 id="schedule">Schedule</h2>
                <h3>TBD</h3>
           </div>


           <div class="col-md-12">
                <h2 id="speakers">Invited Speakers</h2>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://xinw.ai/assets/images/photo.JPG" width="80%" height="auto" style="padding-bottom:30px;">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                    <h3><a href="https://xinw.ai/">Dr. Xin Wang</a></h3>
                    <p>Dr. Xin Wang is a Ph.D. student at UC Berkeley, working with Prof. Trevor Darrell and Prof. Joseph E. Gonzalez. She is part of the BAIR Lab, RISE Lab, and BDD Lab. Her research interest lies at the intersection of computer vision, machine learning and learning systems. </p>
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://www3.cs.stonybrook.edu/~hling/photo/Ling-18.jpg" width="60%" height="auto" style="padding-bottom:30px;">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                    <h3><a href="https://www3.cs.stonybrook.edu/~hling/">Prof. Haibin Ling</a></h3>
                    <p>SUNY Empire Innovation Professor at Stony Brook University. His research interests include computer vision, augmented reality, medical image analysis, visual privacy protection, and human computer interaction. He received Best Student Paper Award of ACM UIST in 2003 and NSF CAREER Award in 2014. He serves as associate editors for IEEE Trans. on Pattern Analysis and Machine Intelligence (PAMI), Pattern Recognition (PR), and Computer Vision and Image Understanding (CVIU). He has served as Area Chairs various times for CVPR and ECCV.</p>
                  </div>
                </div>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://www.crcv.ucf.edu/wp-content/uploads/2018/10/Dr_Shah.jpg" width="60%" height="auto" style="padding-bottom:30px;">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                    <h3><a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Prof. Mubarak Shah</a></h3>
                    <p>Trustee Chair Professor of Computer Science, is the founding director of the Center for Research in Computer Vision at UCF. His research interests include: video surveillance, visual tracking, human activity recognition, visual analysis of crowded scenes, video registration, UAV video analysis, etc. Dr. Shah is a fellow of the National Academy of Inventors, IEEE, AAAS, IAPR and SPIE. In 2006, he was awarded a Pegasus Professor award, the highest award at UCF.</p>
                  </div>
                </div>
           </div>

           <div class="col-md-12">
                <h2 id="committee">Advisory Committee</h2>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://chavdarova.github.io/photos/Tatjana_Chavdarova2.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                      <img src="https://www3.cs.stonybrook.edu/~hling/photo/Ling-18.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                      <img src="http://users.eecs.northwestern.edu/~yingwu/images/wy_2.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-4">
                    <h3><a href="https://chavdarova.github.io">Dr. Tatjana Chavdarova</a></h3>
                    <p>Postdoctoral researcher in the Machine Learning and Optimization (MLO) lab at EPFL.</p>
                  </div>
                  <div class="col-lg-4">
                    <h3><a href="https://www3.cs.stonybrook.edu/~hling/">Prof. Haibin Ling</a></h3>
                    <p>SUNY Empire Innovation Professor, Dept of Computer Science, Stony Brook University.</p>
                  </div>
                  <div class="col-lg-4">
                    <h3><a href="http://users.eecs.northwestern.edu/~yingwu/">Prof. Ying Wu</a></h3>
                    <p>Full professor in the Department of Electrical Engineering and Computer Science and the Department of Computer Science at Northwestern University.<p>
                  </div>
                </div>
                <div class="row">
                  <div class="col-lg-4">
                      <img src="https://lh5.googleusercontent.com/-dV93x6frPFw/UTkTgJT7huI/AAAAAAAAalA/XhMeDDCaHSs/w448-h375-o-k/Jiebo-Bigdata.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                      <img src="https://faculty.ucmerced.edu/mhyang/images/mhyang2005_70.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-4">
                      <img src="https://www.crcv.ucf.edu/wp-content/uploads/2018/10/Dr_Shah.jpg" width="60%" height="auto">
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-4">
                    <h3><a href="https://cs.rochester.edu/u/jluo/">Prof. Jiebo Luo</a></h3>
                    <p>Fully Professor at Department of Computer Science, University of Rochester.</p>
                  </div>
                  <div class="col-lg-4">
                    <h3><a href="https://faculty.ucmerced.edu/mhyang/">Prof. Ming-Hsuan Yang</a></h3>
                    <p>SUNY Empire Innovation Professor, Dept of Computer Science, Stony Brook University.</p>
                  </div>
                  <div class="col-lg-4">
                    <h3><a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Prof. Mubarak Shah</a></h3>
                    <p>UCF Trustee Chair Professor, Director.<p>
                  </div>
                </div>
        </div>
        <div class="col-md-12">
                <h2 id="organizers">Organizers</h2>
                <div class="row">
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-3">
                    <h4>Xiaotian Han</h4>
                  </div>
                  <div class="col-lg-3">
                    <h4>Quanzeng You</h3>
                  </div>
                  <div class="col-lg-3">
                    <h4>Peng Chu</h4>
                  </div>
                  <div class="col-lg-3">
                    <h4>Will Boyd</h3>
                  </div>
                </div>

                <div class="row">
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                  <div class="col-lg-3">
                      <img src="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/03/avatar_user__1490216903-360x360.jpg" width="60%" height="auto" style="border-radius: 50%">
                  </div><!-- /.col-lg-4 -->
                </div>
                <div class="row">
                  <div class="col-lg-3">
                    <h4>Houdong Hu</h4>
                  </div>
                  <div class="col-lg-3">
                    <h4>Jia Li</h3>
                  </div>
                  <div class="col-lg-3">
                    <h4>Jiang Wang</h4>
                  </div>
                  <div class="col-lg-3">
                    <h4>Zicheng Liu</h3>
                  </div>
               </div>
            </div>
        </div>

    </div>
    <!-- /.container -->
    
    <!-- Other people may like it too! -->
    <a style="color:#b5bec9;font-size:0.8em; float:right;" href="https://github.com/mavroudisv/plain-academic">Plain Academic</a> 

    <footer style="background-color:#444; color:#fdfdfd; padding:40px 0;">
        <p style="text-align:center; font-family: sans-serif; font-size: 14px;">
          Workshop and Challenge questions?<br/>
          Email <a href="iccv2021mmp@outlook.com">iccv2021mmp@outlook.com</a><br/>
          Microsoft Azure Computer Vision Team
        </p>
    </footer>
    
</body>

</html>
